{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfd633a1-da12-4c07-878f-662718096ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6909e36-6af1-4c00-ba2c-a4d9593692e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3111859, 118)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('/Users/tarunreddy/Desktop/Projects/Mushroom_Kaggle/clean_mush.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67528d2-f28a-49f9-9888-2687324f83b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['class', 'cap-diameter', 'does-bruise-or-bleed', 'stem-height', 'stem-width', 'has-ring', 'cap-shape_b', 'cap-shape_c', 'cap-shape_f', 'cap-shape_o', 'cap-shape_p', 'cap-shape_s', 'cap-shape_x', 'cap-surface_d', 'cap-surface_e', 'cap-surface_g', 'cap-surface_h', 'cap-surface_i', 'cap-surface_k', 'cap-surface_l', 'cap-surface_s', 'cap-surface_t', 'cap-surface_unknown', 'cap-surface_w', 'cap-surface_y', 'cap-color_b', 'cap-color_e', 'cap-color_g', 'cap-color_k', 'cap-color_l', 'cap-color_n', 'cap-color_o', 'cap-color_p', 'cap-color_r', 'cap-color_u', 'cap-color_w', 'cap-color_y', 'gill-attachment_a', 'gill-attachment_d', 'gill-attachment_e', 'gill-attachment_p', 'gill-attachment_s', 'gill-attachment_unknown', 'gill-attachment_x', 'gill-spacing_c', 'gill-spacing_d', 'gill-color_b', 'gill-color_e', 'gill-color_f', 'gill-color_g', 'gill-color_k', 'gill-color_n', 'gill-color_o', 'gill-color_p', 'gill-color_r', 'gill-color_u', 'gill-color_w', 'gill-color_y', 'stem-root_b', 'stem-root_c', 'stem-root_r', 'stem-root_s', 'stem-root_unknown', 'stem-surface_g', 'stem-surface_h', 'stem-surface_i', 'stem-surface_k', 'stem-surface_s', 'stem-surface_t', 'stem-surface_unknown', 'stem-surface_y', 'stem-color_b', 'stem-color_e', 'stem-color_f', 'stem-color_g', 'stem-color_k', 'stem-color_l', 'stem-color_n', 'stem-color_o', 'stem-color_p', 'stem-color_r', 'stem-color_u', 'stem-color_w', 'stem-color_y', 'veil-type_u', 'veil-color_e', 'veil-color_k', 'veil-color_n', 'veil-color_u', 'veil-color_w', 'veil-color_y', 'ring-type_e', 'ring-type_g', 'ring-type_l', 'ring-type_m', 'ring-type_p', 'ring-type_r', 'ring-type_unknown', 'ring-type_z', 'spore-print-color_g', 'spore-print-color_k', 'spore-print-color_n', 'spore-print-color_p', 'spore-print-color_r', 'spore-print-color_u', 'spore-print-color_unknown', 'spore-print-color_w', 'habitat_d', 'habitat_g', 'habitat_h', 'habitat_l', 'habitat_m', 'habitat_p', 'habitat_u', 'habitat_w', 'season_a', 'season_s', 'season_w']\n"
     ]
    }
   ],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "print(df.columns.tolist())  # Convert to a list and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b4e5a6-8d25-4e8f-afa1-4f9edc51e208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (3111859, 117)\n",
      "Target shape: (3111859,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "X = df.iloc[:, 1:]  # Features (columns 2 to 118)\n",
    "y = df.iloc[:, 0]   # Target (first column)\n",
    "\n",
    "# Check the shapes to confirm the split\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770b0d21-4b0c-4896-b4b9-f1ee8f2c40ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape: (2489487, 117)\n",
      "Validation Features shape: (622372, 117)\n",
      "Training Target shape: (2489487,)\n",
      "Validation Target shape: (622372,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Check the shapes of the splits\n",
    "print(\"Training Features shape:\", X_train.shape)\n",
    "print(\"Validation Features shape:\", X_val.shape)\n",
    "print(\"Training Target shape:\", y_train.shape)\n",
    "print(\"Validation Target shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d5c21d1-6770-439b-88a6-6f6373d339fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Training Features:\n",
      "          cap-diameter  does-bruise-or-bleed  stem-height  stem-width  \\\n",
      "2175463      2.033525                   1.0     1.104270    2.249906   \n",
      "2500832     -0.041329                   0.0    -0.913793   -0.260785   \n",
      "1482972      0.425715                   0.0     0.019122    0.104825   \n",
      "2453502      0.500871                   0.0    -0.300957   -0.481941   \n",
      "1151101      1.145069                   1.0     0.612440    1.608171   \n",
      "\n",
      "         has-ring  cap-shape_b  cap-shape_c  cap-shape_f  cap-shape_o  \\\n",
      "2175463       0.0          0.0          0.0          0.0          0.0   \n",
      "2500832       0.0          0.0          0.0          1.0          0.0   \n",
      "1482972       1.0          0.0          0.0          0.0          0.0   \n",
      "2453502       0.0          0.0          0.0          0.0          0.0   \n",
      "1151101       0.0          0.0          0.0          0.0          0.0   \n",
      "\n",
      "         cap-shape_p  ...  habitat_g  habitat_h  habitat_l  habitat_m  \\\n",
      "2175463          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "2500832          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "1482972          1.0  ...        0.0        0.0        0.0        0.0   \n",
      "2453502          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "1151101          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "\n",
      "         habitat_p  habitat_u  habitat_w  season_a  season_s  season_w  \n",
      "2175463        0.0        0.0        0.0       1.0       0.0       0.0  \n",
      "2500832        0.0        0.0        0.0       0.0       0.0       0.0  \n",
      "1482972        0.0        0.0        0.0       1.0       0.0       0.0  \n",
      "2453502        0.0        0.0        0.0       0.0       0.0       1.0  \n",
      "1151101        0.0        0.0        0.0       1.0       0.0       0.0  \n",
      "\n",
      "[5 rows x 117 columns]\n",
      "Transformed Validation Features:\n",
      "          cap-diameter  does-bruise-or-bleed  stem-height  stem-width  \\\n",
      "2384627      1.759741                   1.0     1.322861    1.698935   \n",
      "2787471     -0.757999                   0.0    -0.960634    0.806642   \n",
      "361643       0.224403                   0.0    -0.933310   -0.011506   \n",
      "1612448      2.076472                   1.0     0.913003    2.547763   \n",
      "3021723      0.734393                   0.0    -0.589810    1.162025   \n",
      "\n",
      "         has-ring  cap-shape_b  cap-shape_c  cap-shape_f  cap-shape_o  \\\n",
      "2384627       0.0          0.0          0.0          0.0          0.0   \n",
      "2787471       0.0          0.0          0.0          0.0          1.0   \n",
      "361643        1.0          0.0          0.0          1.0          0.0   \n",
      "1612448       0.0          0.0          0.0          0.0          0.0   \n",
      "3021723       0.0          0.0          0.0          1.0          0.0   \n",
      "\n",
      "         cap-shape_p  ...  habitat_g  habitat_h  habitat_l  habitat_m  \\\n",
      "2384627          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "2787471          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "361643           0.0  ...        0.0        0.0        0.0        0.0   \n",
      "1612448          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "3021723          0.0  ...        0.0        0.0        0.0        0.0   \n",
      "\n",
      "         habitat_p  habitat_u  habitat_w  season_a  season_s  season_w  \n",
      "2384627        0.0        0.0        0.0       1.0       0.0       0.0  \n",
      "2787471        0.0        0.0        0.0       0.0       0.0       0.0  \n",
      "361643         0.0        0.0        1.0       1.0       0.0       0.0  \n",
      "1612448        0.0        0.0        0.0       0.0       0.0       0.0  \n",
      "3021723        0.0        0.0        0.0       1.0       0.0       0.0  \n",
      "\n",
      "[5 rows x 117 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Assuming the numerical columns are the last 3 in the original data\n",
    "# If you know the exact indices, you can specify them directly.\n",
    "numerical_cols = ['cap-diameter', 'stem-height', 'stem-width']  # Adjust if needed\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and validation sets\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "\n",
    "# Check the transformed data\n",
    "print(\"Transformed Training Features:\\n\", X_train.head())\n",
    "print(\"Transformed Validation Features:\\n\", X_val.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de9f6d-8bb1-48e8-baba-bfa0c0db6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer and first hidden layer\n",
    "model.add(Dense(256, input_dim=117, activation='relu'))\n",
    "model.add(BatchNormalization())  # Optional\n",
    "model.add(Dropout(0.3))  # Optional\n",
    "\n",
    "# Second hidden layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())  # Optional\n",
    "model.add(Dropout(0.3))  # Optional\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())  # Optional\n",
    "model.add(Dropout(0.3))  # Optional\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60edd2-789c-42da-889e-d1de75d65ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba256b5e-d567-48f2-897f-79956fa5e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for early stopping and reducing learning rate\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e521d-5a9f-4f3c-96e6-99ec64ba4280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the training data with verbose output\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=50,  # Adjust this number as needed\n",
    "                    batch_size=1024,  # Experiment with batch sizes\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)  # This will print the loss and metrics for each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d13fbb-1c56-4d61-b8b7-eb9e8d097d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15748390-9bf0-42aa-9e94-40a9ecd38c7f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fab3772-a192-40f0-9a39-91ee038056ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2077964, 118)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df_test = pd.read_csv('/Users/tarunreddy/Desktop/Projects/Mushroom_Kaggle/clean_mush_test.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbf96397-2ae3-4933-8c61-ba5f515a3837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (2077964, 117)\n",
      "Target shape: (2077964,)\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.iloc[:, 1:]  # Features (columns 2 to 118)\n",
    "id = df_test.iloc[:, 0]   # Target (first column)\n",
    "\n",
    "# Check the shapes to confirm the split\n",
    "print(\"Features shape:\", X_test.shape)\n",
    "print(\"Target shape:\", id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9020ffb-3323-45f3-a702-8762887eab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both DataFrames have the same columns in the same order.\n"
     ]
    }
   ],
   "source": [
    "columns_are_equal = (X.columns.tolist() == X_test.columns.tolist())\n",
    "\n",
    "if columns_are_equal:\n",
    "    print(\"Both DataFrames have the same columns in the same order.\")\n",
    "else:\n",
    "    print(\"The DataFrames do not have the same columns in the same order.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dbf61ca-1fd4-4b11-8bc0-d9b7b0a2f91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Training Features:\n",
      "    cap-diameter does-bruise-or-bleed  stem-height  stem-width has-ring  \\\n",
      "0      0.664605                    t     1.877145    0.772127        t   \n",
      "1      0.197561                    f    -1.971617   -0.042186        f   \n",
      "2     -1.117676                    f    -0.055043   -1.015015        f   \n",
      "3     -0.723105                    f    -0.523452   -0.328538        t   \n",
      "4      0.001618                    f     0.159645    0.334929        t   \n",
      "\n",
      "   cap-shape_b  cap-shape_c  cap-shape_f  cap-shape_o  cap-shape_p  ...  \\\n",
      "0          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "1          0.0          0.0          0.0          1.0          0.0  ...   \n",
      "2          1.0          0.0          0.0          0.0          0.0  ...   \n",
      "3          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "4          0.0          0.0          0.0          0.0          0.0  ...   \n",
      "\n",
      "   habitat_g  habitat_h  habitat_l  habitat_m  habitat_p  habitat_u  \\\n",
      "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   habitat_w  season_a  season_s  season_w  \n",
      "0        0.0       1.0       0.0       0.0  \n",
      "1        0.0       1.0       0.0       0.0  \n",
      "2        0.0       0.0       1.0       0.0  \n",
      "3        0.0       0.0       0.0       0.0  \n",
      "4        0.0       0.0       0.0       0.0  \n",
      "\n",
      "[5 rows x 117 columns]\n"
     ]
    }
   ],
   "source": [
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "# Check the transformed data\n",
    "print(\"Transformed Training Features:\\n\", X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d47e0e8d-b068-4edc-8563-cf605525e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be25b99-1ab1-41d4-8ccb-b31c5841321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd821ff4-69a1-4ae7-9b5f-ba149a1837c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to class labels ('p' or 'e')\n",
    "class_labels = ['p' if pred >= 0.5 else 'e' for pred in predictions]\n",
    "\n",
    "# Create a new DataFrame with the id and class labels\n",
    "results_df = pd.DataFrame({\n",
    "    'id': id,\n",
    "    'class': class_labels\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('predictions_1.csv', index=False)\n",
    "\n",
    "print(\"CSV file with predictions created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca245d-042a-4249-af5f-13ebf75de381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
